---
title: 'Hallucinating Art Models, Sound Design in Python, and a little Canvas'
author: Chris Ried
date: '2022-10-03'
slug: generative-arts-50
categories: 
featured: 
tags: ['generative']
---

_Originally posted on [Substack](https://generative.substack.com/p/hallucinating-art-models-sound-design)_


> Make things happen, Don't let things happen to you. -Syed Sharukh


Hello creatives! 

Iâ€™ve been spending quite a bit of time learning a bunch of technologies in the last year to continue stepping up the various skills needed to really try what I have in my mind. Much of it has to do with in real life materials but using generative techniques to really drive it and so I hope to share in the future. 

![CleanShot 2022-10-02 at 19.49.33.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e4335302-f291-4b78-9765-495d78d1d4e6/CleanShot_2022-10-02_at_19.49.33.png)

Another thing I had been working on was really getting into using the canvas API (as opposed to [p5js](https://p5js.org/) or something similar), I wrote a little [tutorial](https://observablehq.com/@cdr6934/getting-to-know-canvas) while I was working with it and thought I might share it with you all. Itâ€™s plain but it helped me find some of the bearings using [Observable](https://observablehq.com/). All of the code is hidden when you first look at it but each of the graphics (look for the  â–· on the side) provides the code to study and Iâ€™ve added a few tips as I was writing. Hopes itâ€™s beneficial if you havenâ€™t worked with canvas. 

Have a great week! 

Chris 

# ğŸ–Œï¸ Unconventional Media

{{ youtube 3s94mIhCyt4 }}

> I embarked on a year-long journey to find a way to print a 5-piece fashion collection as part of my graduate collection at Shenkar. Using soft materials and flexible patterns, I printed this collection at home.
> 

I do have a special spot in my heart for 3D printed materials as it really another medium of creativity. Though a number of years old, it just comes to show just how interesting new mediums can provide alternative avenues of creation and generation. 

# ğŸµ Generative Sound

{{ youtube Q40qEg8Yq5c }}

## Drop the Daw: Sound Design in Python

The above [tutorial](https://data.audio.dev/talks/2020/sound-design-in-python/slides.pdf) uses Python to provide an alternative solution to the more common C++ libraries, which is understandable for the virtual instrument but not for quick iteration.  The presentation a solid first start into the realm of sound design using Python. 

# ğŸ¨ AI Art

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2914dadb-90dd-4ea5-9539-17e78453f959/Untitled.png)

## ****[Hallucinating with art models](https://meowni.ca/posts/hallucinations/)****

> Wow, long time, no posts! Anyway, about them text-to-art generative models going about, eh? Surprising nobody: I am extremely into them. Iâ€™ve been usingÂ **[DALL-E](https://openai.com/dall-e-2/)**Â andÂ **[MidJourney](https://www.midjourney.com/home/)**Â since they came out, and even though tons has been written about them, I wanted to give a slightly different overview: the perspective of someone who isnâ€™t interested that much in their realism skills.
> 

![CleanShot 2022-10-02 at 12.01.10.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f48c2232-d55f-4856-9123-81dd9366e59b/CleanShot_2022-10-02_at_12.01.10.png)

## [KREA](https://www.krea.ai/)

KREA is a tool to help find unique prompts for Stable Diffusion. Essentially it is a search engine for stable diffusion prompts which will help users find a particular aesthetic generated by deep learning. Itâ€™s a worthwhile thing to try if you havenâ€™t played with it yet. 

And if you want to just have a [quicker browse](https://gorgeous.adityashankar.xyz/) how asking the model about the style of the image.. this is a really neat small tool that gives you the work as well here. 

![CleanShot 2022-10-03 at 09.22.26.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/341789b0-fcce-4a7d-b42f-63e673a1e0a5/CleanShot_2022-10-03_at_09.22.26.png)

I find these sites to be great for inspiration and the many creative ways one might discover interesting ways to generate interesting images as they explore the model and itâ€™s potential. Also, if you have an M1 Mac and want to play with the model, [Charl-e](https://www.charl-e.com/) is a great piece of software you can use and works quite well. 

![CleanShot 2022-10-02 at 20.03.24.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c5b81160-898c-4f6b-8663-590fb61202dd/CleanShot_2022-10-02_at_20.03.24.png)

## [Dreamfusion: **Text-to-3D using 2D Diffusion**](https://dreamfusion3d.github.io/gallery.html)

> Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.
> 

# ğŸª› Techniques

![CleanShot 2022-10-02 at 20.22.56@2x.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dd0b6583-0b70-40c3-b3eb-afff001460b3/CleanShot_2022-10-02_at_20.22.562x.png)

## ****[An Algorithm for Polygon Intersections](https://gorillasun.de/blog/an-algorithm-for-polygon-intersections)****

> This article initially began as a short post discussing strategies that can determine rectangle intersections and collisions, for both axis-aligned rectangles as well as arbitrarily rotated rectangles. While working on a recent project however, I discovered that this intersection test can be extended to not only return the polygonal shape that is formed by the intersection of two non-axis aligned rectangles but also that of two convex polygons. Hence I extended the post to include this information as well. By [GorillaSun](https://twitter.com/gorillasu)
> 

# ğŸ“šBooks

![CleanShot 2022-10-02 at 12.07.28.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7af517cf-0fd6-4121-8441-2e79ef876c5e/CleanShot_2022-10-02_at_12.07.28.png)

## Machine Hallucinations: Architecture and Artificial Intelligence

Not to be confused with the work of [Refik Anadol](https://refikanadol.com/) This is volume 92 of Architectural Design and I found this as an inspirational piece of using Deep Learning techniques to generate images and textures to be used in the domain of architecture. But there are a number of articles inside that feature the likes of [Sofia Crespo](https://sofiacrespo.com/) in â€œAugmenting Digital Natureâ€ 

# Send me your inspirations...