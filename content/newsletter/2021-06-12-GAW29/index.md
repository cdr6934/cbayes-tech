---
title: 'Bonsai Trees, Color History and Depth Estimation'
author: Chris Ried
date: '2021-06-12'
slug: generative-arts-29
categories: 
featured: 
tags: ['generative']
---

_Originally posted on [Substack](https://generative.substack.com/p/bonsai-trees-color-history-and-depth)_
> "The absence of limitations is the enemy of art." - *Orson Welles*
> 

The discipline of trimming and waiting, the bonsai master takes the medium of the tree and molds it using wire as a way to encourage the shape of growth. Throughout the years he cuts, and prunes, sheers and replants and cuts some more.

 Once in a while he moves the tree to a new pot, sifting through the roots system looking for only the living and then places the bonsai back into position.

At times he will make choices of exposing only the trunk, the rawest form of the tree. Wood, not necessarily the liveliest looking part of the plant, yet the most important. As it feeds the rest of the tree through it's root system. 

Over the years as the sapling matures, it becomes the essence of the mature tree it would have grown to be. 

A living sculpture, a triumphant image that is unique in its own right. 

{{ youtube fCdXvp0tTnc }}

> This first episode from Bonsai Releaf documents the designing, pruning and shaping of a Juniper bonsai tree.
> 

So what can we learn from this, though the tree is living, we see an archetype of the pattern of creation in generative art. 

The agent - the actual tree continues to grow in its own pattern unalterable by recipe. 

The algorithmic choice - the wire used to coax the tree into certain shapes 

The curation - snipping off new sprouts, concentrating at the core of its shapes 

The display - the pot / moss can drive the aesthetic quite explicitly 

The code cultivation - making sure that the plant has access to water and sunlight 

Of course it is not one in the same, but I do believe there is value to understanding the ways of other disciplines to help refine and continue to push the bounds of the artist's practice. Also, there is a pattern of creativity that emerges when looking into any discipline. 

So here are a few takeaways: 

- There are times, when some art can take alot of effort and time to become its own self
- Curation can be brutal, but it provides a mechanism to get into a realm of beauty or meaning
- The practice never is mastered, you only become more fluent in its language
- Though limited to species of tree, it can be formed into greatness

Hope you have a great weekend!

 Chris Ried 

# News

# Fidenza - Tyler Hobbs ðŸŽ†

[Artblocks.io](http://artblocks.io) has released another amazing generative art minting by the wonderful Tyler Hobbs. Tyler describes as  follows: 

> Fidenza is by far my most versatile algorithm to date. Although the program stays focused on structured curves and blocks, the varieties of scale, organization, texture, and color usage it can employ create a wide array of generative possibilities.
> 

**Fidenza #177**

A portion of these are available on the secondary market to be bought at [OpenSea](https://opensea.io/assets/art-blocks?search[resultModel]=ASSETS&search[stringTraits][0][name]=Fidenza&search[stringTraits][0][values][0]=All%20Fidenzas). 

Also check out the following [interview](https://www.youtube.com/watch?v=pTesZREe73c) I had the honor of partaking in a couple months ago. 

# Future Creative Coding Tools

Thanks to the Future Sketches Talks by the MIT Media lab hosted by Zac Lieberman. The series talked with [Phoenix Perry](https://mit.zoom.us/rec/play/MmAZGkw94hRbLudgLWfW3NolMsCKVhw1_CIOzAa2bz8DTB4rfxTVKosxkNctoD9QLxrs3iHLfLP2RQ4.Q5dyClqgiDkcCavc?_x_zm_rhtaid=470&_x_zm_rtaid=uAwdNlHCT3-fLhyXozcsgA.1621008874097.a2db27cfb200aa3c632049cf5d71be5c&autoplay=true&continueMode=true&startTime=1620835211000), [Baku Hasimoto](https://mit.zoom.us/rec/share/H9FyRt_JDjFh2UognOBr3AuGeHts3f128d5vlUuJ64JuX5_7aJA_OkA0jD2DjK0t.VN86tdpeSPH7FIjP?startTime=1621440014000), [Patricio Gonzalez Vivo](https://mit.zoom.us/rec/play/m73QTieKNKOcE-gQUVT3KDybS-F9QMLVAV2uo35RL3iJevumsO0tjZOaKPt29KbaFpLPvzk2cHx8icAU.1_B4X9-Ykrj28-Kk?_x_zm_rhtaid=478&_x_zm_rtaid=u6edBOS6SoiEiaqSWY7r2Q.1622302016997.83736c6d867647bec920240dfa5b41af&autoplay=true&continueMode=true&startTime=1622045133000), and [Matt DesLauriers](https://mit.zoom.us/rec/play/miK2Z8Vd1IUZ01JnqFKSZFZ3fL_4-YiSMgHKUI21R3RlDPVZ7tLk9i6tKnWApKIh_KpIt-HW_cIkSxYE.HctbnOpN5NxQBbh7?_x_zm_rhtaid=6&_x_zm_rtaid=rNgVm195Sn6LytHLlNSI8w.1622654054075.42ba099865396f4d5df6bc2aa0eeaf88&autoplay=true&continueMode=true&startTime=1622649925000) about the tools that they were currently creating and what their vision for the future of their tools looked like: 

- [InteractML](http://interactml.com/) - Based on the Unity extension
- [GLISP](https://glisp.app/commit:e7fbaae/) - Lisp based graphics package in the browser
- [GLSLIFY](https://github.com/glslify/glslify)  - A command line tool for shader tools
- [Canvas - Sketch](https://github.com/mattdesl/canvas-sketch/blob/master/docs/installation.md) - A javascript package of tools to doing creative coding in the browser

# ðŸ”– Articles and Tutorials

## The Captivating Invention of Color

{{ youtube QxGAofhYi7M }}

> Sensory export Carolyn Purnell shares the fascinating history of color and how color revolutions have changed the course of history. Carolyn Purnell is a history instructor, writer, and lover of all things colorful and offbeat. She is the author of The Sensational Past: How the Enlightenment Changed the Way We Use Our Senses (Norton, 2017) and the forthcoming Inventing Color. Carolyn earned her Ph.D. in history from University of Chicago, and her work has appeared in Wall Street Journal, CityLab by The Atlantic, Good Housekeeping, and Apartment Therapy. She has received fellowships from the National Endowment for the Humanities, Huntington Library, the Georges Lurcy Foundation, the Brown Foundation of Fellows, and the French Society for Historical Studies.
> 

Lately I've been searching through the Observable archives and have found some pretty impressive stuff. Not only is it visually appealing, but there is code! A great opportunity to discover and hone your skillset if you use javascript.

   

## [Creating Animated Art Stream](https://observablehq.com/@mkfreeman/creating-animated-art-stream)

Here we have the wonderful Lionel Raddisson and Matt Dzugan who walk through their process using Observable and Javascript to create some of their amazing work. 

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a30afe97-ae3a-4eaf-8a07-92b6395b862f/Screen_Shot_2021-06-10_at_10.11.11_AM.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a30afe97-ae3a-4eaf-8a07-92b6395b862f/Screen_Shot_2021-06-10_at_10.11.11_AM.png)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/51e58a0d-5175-4ccb-a9de-f983d53bd9ab/687474703a2f2f79616b736f792e6769746875622e696f2f696d616765732f687264657074685465617365722e6a7067.jpeg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/51e58a0d-5175-4ccb-a9de-f983d53bd9ab/687474703a2f2f79616b736f792e6769746875622e696f2f696d616765732f687264657074685465617365722e6a7067.jpeg)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/916b31b1-cea9-4fbd-9243-d74d9942cc14/Screen_Shot_2021-06-09_at_8.39.09_AM.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/916b31b1-cea9-4fbd-9243-d74d9942cc14/Screen_Shot_2021-06-09_at_8.39.09_AM.png)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a28fae36-1d49-45e8-865d-75c7b8ccfb44/78000177.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a28fae36-1d49-45e8-865d-75c7b8ccfb44/78000177.png)

## [Building a Parametric Seashell](https://observablehq.com/@bronna/parametric-seashell)

> Learn about the underlying geometry of seashells, and how to modify the structure on your own, with these interactive WebGL models. The models are built with regl and are based on the paper Seashells: The Plainness and Beauty of their Mathematical Description by Jorge Picado
> 

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/add71be7-e889-4755-9db0-6fa945d2d1a4/Screen_Shot_2021-06-09_at_8.40.23_AM.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/add71be7-e889-4755-9db0-6fa945d2d1a4/Screen_Shot_2021-06-09_at_8.40.23_AM.png)

## [Rendering a Cube in threeJS in SVG anaglyph](https://observablehq.com/@tonyhschu/rendering-a-cube-in-threejs-in-svg-anaglyph)

There isn't any narrative in this notebook, however it is a fascinating opportunity to use three.js to create stereoscopic imagery. Its a simple example, however there are a number of fun retro use cases! 

![http://www.elopezr.com/wp-content/uploads/2021/05/Nanite-Full-GBuffer.jpg](http://www.elopezr.com/wp-content/uploads/2021/05/Nanite-Full-GBuffer.jpg)

## [A Macro View of Nanite](http://www.elopezr.com/a-macro-view-of-nanite/)

> After showing an impressive demo last year and unleashing recently with the UE5 preview, Nanite is all the rage these days. I just had to go in and have some fun trying to figure it out and explain how I think it operates and the technical decisions behind it using a renderdoc capture. Props to Epic for being open with their tech which makes it easier to learn and pick apart; the editor has markers and debug information that are going to be super helpful.
> 

# Future Creative Coding Tools

Thanks to the Future Sketches Talks by the MIT Media lab hosted by Zac Lieberman. The series talked with [Phoenix Perry](https://mit.zoom.us/rec/play/MmAZGkw94hRbLudgLWfW3NolMsCKVhw1_CIOzAa2bz8DTB4rfxTVKosxkNctoD9QLxrs3iHLfLP2RQ4.Q5dyClqgiDkcCavc?_x_zm_rhtaid=470&_x_zm_rtaid=uAwdNlHCT3-fLhyXozcsgA.1621008874097.a2db27cfb200aa3c632049cf5d71be5c&autoplay=true&continueMode=true&startTime=1620835211000), [Baku Hasimoto](https://mit.zoom.us/rec/share/H9FyRt_JDjFh2UognOBr3AuGeHts3f128d5vlUuJ64JuX5_7aJA_OkA0jD2DjK0t.VN86tdpeSPH7FIjP?startTime=1621440014000), [Patricio Gonzalez Vivo](https://mit.zoom.us/rec/play/m73QTieKNKOcE-gQUVT3KDybS-F9QMLVAV2uo35RL3iJevumsO0tjZOaKPt29KbaFpLPvzk2cHx8icAU.1_B4X9-Ykrj28-Kk?_x_zm_rhtaid=478&_x_zm_rtaid=u6edBOS6SoiEiaqSWY7r2Q.1622302016997.83736c6d867647bec920240dfa5b41af&autoplay=true&continueMode=true&startTime=1622045133000), and [Matt DesLauriers](https://mit.zoom.us/rec/play/miK2Z8Vd1IUZ01JnqFKSZFZ3fL_4-YiSMgHKUI21R3RlDPVZ7tLk9i6tKnWApKIh_KpIt-HW_cIkSxYE.HctbnOpN5NxQBbh7?_x_zm_rhtaid=6&_x_zm_rtaid=rNgVm195Sn6LytHLlNSI8w.1622654054075.42ba099865396f4d5df6bc2aa0eeaf88&autoplay=true&continueMode=true&startTime=1622649925000) about the tools that they were currently creating and what their vision for the future of their tools looked like: 

- [InteractML](http://interactml.com/) - Based on the Unity extension
- [GLISP](https://glisp.app/commit:e7fbaae/) - Lisp based graphics package in the browser
- [GLSLIFY](https://github.com/glslify/glslify)  - A command line tool for shader tools
- [Canvas - Sketch](https://github.com/mattdesl/canvas-sketch/blob/master/docs/installation.md) - A javascript package of tools to doing creative coding in the browser

- [https://www.npmjs.com/package/saxi](https://www.npmjs.com/package/saxi)
- [https://axifigma.steftervel.de/](https://axifigma.steftervel.de/)

## [Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging](https://github.com/compphoto/BoostingMonocularDepth)

> Neural networks have shown great abilities in estimating depth from a single image. However, the inferred depth maps are well below one-megapixel resolution and often lack fine-grained details, which limits their practicality. Our method builds on our analysis on how the input resolution and the scene structure affects depth estimation performance. We demonstrate that there is a trade-off between a consistent scene structure and the high-frequency details, and merge low- and high-resolution estimations to take advantage of this duality using a simple depth merging network. We present a double estimation method that improves the whole-image depth estimation and a patch selection method that adds local details to the final result. We demonstrate that by merging estimations at different resolutions with changing context, we can generate multimegapixel depth maps with a high level of detail using a pre-trained model.
> 

![https://miro.medium.com/max/3840/1*5tmD1Ey9XNciA_FQYGJl6g.png](https://miro.medium.com/max/3840/1*5tmD1Ey9XNciA_FQYGJl6g.png)

## [Creative Collaboration with AI](https://towardsdatascience.com/creative-collaboration-with-ai-27350232cdc4)

> There are more and more models, solutions, and applications with ML/DL-powered generative force. It allows you to augment your abilities and skills, realize your visions and create your dreams with the help of various AI models and apps
> 

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bd4fe30a-931a-4c75-b18f-59b686848ba9/Screen_Shot_2021-06-07_at_10.16.47_AM.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bd4fe30a-931a-4c75-b18f-59b686848ba9/Screen_Shot_2021-06-07_at_10.16.47_AM.png)

## [WebGL Fundamentals](https://webglfundamentals.org/webgl/lessons/webgl-fundamentals.html)

> WebGL (Web Graphics Library) is often thought of as a 3D API. People think "I'll use WebGL and magic I'll get cool 3d". In reality WebGL is just a rasterization engine. It draws points, lines, and triangles based on code you supply. Getting WebGL to do anything else is up to you to provide code to use points, lines, and triangles to accomplish your task.
> 

# Send me your inspirations...