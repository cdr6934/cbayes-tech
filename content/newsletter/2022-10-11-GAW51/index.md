---
title: 'FFMPEG Video Art, Generative Audio and Ken Perlin'
author: Chris Ried
date: '2022-10-11'
slug: generative-arts-51
categories: 
featured: 
tags: ['generative']
---

_Originally posted on [Substack](https://generative.substack.com/p/ffmpeg-video-art-generative-audio)_

> Silence creates space for content to appear. -J.R. Rim
> 

## Video Art with FFMPEG

{{ youtube nobWeGycSe8 }}

One of the many tools we use to describe motion is in a sequence of images or videos. We love them and use them for our work as it adds yet another dimension to the images. The following few selections all use [FFMPEG](https://ffmpeg.org/) an open source tool to convert video from different formats in the command line or through a programming language. But there are a few more creative uses of this tool and [Derrick Schultz](https://artificial-images.com/) has a great [4 week video course](https://docs.google.com/document/d/12X_2YoCnPPN7B3OsgX39aYyRF8OF-TVStkFTkKhWrx4/edit) that he uses the tools in creative ways and provides code artists another way to create some interesting work. 

If you are looking for a quicker fix,  this presentation by Matic Lubej on ffmpeg is an overview on how to use FFMPEG specifically in Python using it creatively. 

{{ youtube vivlxlxGkX4 }}

# ğŸ–Œï¸ Unconventional Media

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f32923ed-ea8e-4286-9417-55ae5cf72ff8/Untitled.png)

## **[Matrix-Webcam](https://github.com/joschuck/matrix-webcam)**

> This package displays your webcam video feed in the console.
> 

Its a fun little tool to play around with; its open source so the [code](https://github.com/joschuck/matrix-webcam/blob/main/matrix_webcam/__main__.py)â€¦ 

# ğŸ“¸ Generative Graphics

{{ youtube 7He2MDAOI38 }}

## Ken Perlin - How to Build a Holodeck

> In the age of COVID-19 it is more clear than ever that there is a compelling need for better remote collaboration.  Fortunately a number of technologies are starting to converge which will allow us to take such collaborations to a whole new level.  Imagine that when you join an on-line meeting you are present with your entire body, and that you can see and hear other people as though you are all in the same room. There are many challenges to realizing this vision properly.  The NYU Future Reality Lab and its collaborators are working on many of them.  This talk will give an overview of many of the key areas of research, including how to guarantee universal accessibility, user privacy and rights management, low latency networking, design and construction of shared virtual worlds, correct rendering of spatial audio, biometric sensing, and a radical rethinking of user interface design.
> 

![CleanShot 2022-10-11 at 09.58.50.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/feefb624-5fb7-4a51-9ce5-3bd10232730f/CleanShot_2022-10-11_at_09.58.50.png)

## [Color Palette from Image](https://observablehq.com/@cpreid2/get-color-palette-from-image)

The following [Observable](https://observablehq.com/) notebook has an example of using the [Vibrant.js](https://jariz.github.io/vibrant.js/) library. Itâ€™s an interesting way to help choosing color palettes from a specific image. 

# ğŸš¤ AI / Deep Learning

[https://imagen.research.google/video/videos/fairytale-2.mp4](https://imagen.research.google/video/videos/fairytale-2.mp4)

## [IMAGEN VIDEO](https://imagen.research.google/video/)

> We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding.
> 

We have seen alot of innovation in the image space when it comes to generative deep learning models. There is some interesting work in the audio generation / audio processing space as well. The following are a few more interesting work 

[https://vimeo.com/747192462](https://vimeo.com/747192462)

## [Neutone](https://neutone.space/)

> Neutone is a go-to platform for you to share real-time AI audio processing models with potential users in the audio production community.
> 

{{ youtube  KmB8z2CYjZY }}

## [Harmonai AI, Diffusion and Audio Generation Revolution](https://www.youtube.com/watch?v=KmB8z2CYjZY&t=1s)

> Listen to Harmonai core team's vision and how their Dance Diffusion model is the first step on the journey to high quality music and audio generation for everyone.
> 

# ğŸ”– Articles and Tutorials

{{ youtube A1Ud_liFn3U }}

## Joshua Davis - Dribble Conference 2019

> Joshua Davis is a design polymathâ€”designer, technologist, author & artist who has used creative coding to generate algorithmic images and animations since 1995.
> 

Josh Davis is one of the most prolific artist / designers and so much of his work provides a historical context on the progression of early generative works from 1995 to 2001. 

# ğŸ“šBooks

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1bf4ce33-2785-409f-8e51-aa55539e7b6c/Untitled.png)

## [Real-Time 3D Graphics with WebGL2](https://www.amazon.com/Real-Time-Graphics-WebGL-interactive-applications-ebook/dp/B07GVNQLH5/ref=sr_1_1?crid=30AQ05FZK9O4R&keywords=Real-Time+3D+Graphics+with+WebGL2&qid=1665502690&qu=eyJxc2MiOiIxLjU3IiwicXNhIjoiMC4wMCIsInFzcCI6IjAuMDAifQ%3D%3D&sprefix=real-time+3d+graphics+with+webgl2+%2Caps%2C65&sr=8-1)

> This book presents a clear roadmap to learning real-time 3D computer graphics with WebGL 2. Each chapter starts with a summary of the learning goals for the chapter, followed by a detailed description of each topic. The book offers example-rich, up-to-date introductions to a wide range of essential 3D computer graphics topics, including rendering, colors, textures, transformations, framebuffers, lights, surfaces, blending, geometry construction, advanced techniques, and more. With each chapter, you will "level up" your 3D graphics programming skills. This book will become your trustworthy companion in developing highly interactive 3D web applications with WebGL and JavaScript.
> 

# Tools

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b886c024-7406-4f7c-afc1-9d409614ec37/Untitled.png)

## **[ct.js: 2D Game Editor](https://ctjs.rocks/)**

> ct.js makes learning programming fun and game development easy by its visual tools, good docs and flexible, modular library. It is free, open-source, and is loved by hobbyists, professionals, teachers, and their students.
> 

# Send me your inspirations...